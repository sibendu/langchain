{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738680c8-5c54-4ea5-b9a8-142d3d73dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The pipeline for QA over code follows the steps we do for document question answering, with some differences:\n",
    "#   In particular, we can employ a splitting strategy that does a few things:\n",
    "#     Keeps each top-level function and class in the code is loaded into separate documents.\n",
    "#     Puts remaining into a separate document.\n",
    "#     Retains metadata about where each split comes from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "354ce261-54af-445c-98e0-2c45382b0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.config import load_configuration\n",
    "\n",
    "PROP_FILE = 'app.properties'\n",
    "configs = load_configuration(PROP_FILE)\n",
    "\n",
    "API_TYPE = configs.get(\"API_TYPE\").data\n",
    "API_VERSION = configs.get(\"API_VERSION\").data\n",
    "API_KEY = configs.get(\"API_KEY\").data\n",
    "API_BASE = configs.get(\"API_BASE\").data\n",
    "LLM_ENGINE_GPT35_16K=configs.get(\"LLM_ENGINE_GPT35_16K\").data\n",
    "ADA_MODEL=configs.get(\"ADA_MODEL\").data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "098d2f82-45b7-42f6-aa2e-e4435082fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import LanguageParser\n",
    "from langchain_text_splitters import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d86e18-7f1c-40bd-b1c3-650efb4e8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone\n",
    "repo_path = \"/mnt/c/Temp/code_analysis_llm\"\n",
    "repo = Repo.clone_from(\"https://github.com/sibendu/KafkaReader\", to_path=repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e28575-9e47-44f2-b790-54fda9f849b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load\n",
    "loader = GenericLoader.from_filesystem(\n",
    "    repo_path + \"/src/main/java\",\n",
    "    glob=\"**/*\",\n",
    "    suffixes=[\".java\"],\n",
    "    exclude=[\"**/non-utf8-encoding.py\"],\n",
    "    parser=LanguageParser(language=Language.JAVA, parser_threshold=500),\n",
    ")\n",
    "documents = loader.load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baa36e41-1487-4f90-8a55-a66c9d1e18e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.JAVA, chunk_size=2000, chunk_overlap=200\n",
    ")\n",
    "texts = python_splitter.split_documents(documents)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acfb3847-a714-40b0-8d7e-da2edf28a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=API_BASE,\n",
    "    api_key=API_KEY,\n",
    "    azure_deployment=LLM_ENGINE_GPT35_16K,\n",
    "    openai_api_version=API_VERSION,\n",
    ")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=API_BASE,\n",
    "    azure_deployment=ADA_MODEL,\n",
    "     api_key=API_KEY,\n",
    "    openai_api_version=API_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d6db452-4323-4c31-8322-68fcfd45025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "vector = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d274099-64e5-41e7-b3ef-60a8941a8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector.as_retriever(\n",
    "    search_type=\"mmr\",  # Also test \"similarity\"\n",
    "    search_kwargs={\"k\": 8},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38e768ac-2943-433d-bac6-cee494e0ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chat\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Given the above conversation, generate a search query to look up to get information relevant to the conversation\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user's questions based on the below context:\\n\\n{context}\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "qa = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5921cc6-bad0-4f3e-86a7-983d5c7f99fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The processing steps in the `processMessage` method are as follows:\\n\\n1. Parse the message JSON and extract the required fields such as `serialNumber`, `objectType`, `objectId`, `terminalName`, `inetName`, `siteName`, `satelliteName`, `spaceCraftName`, `teleportName`, `beamName`, `serviceArea`, `customerName`, `terminalType`, `mobilityType`, `terminalModel`, `streamType`, `resolution`, and `timestamp`.\\n2. Parse the timestamp string and convert it to a Date object.\\n3. Extract the `metrics` JSON object from the message.\\n4. Extract the metric name and value from the metrics JSON object.\\n5. Check if the metric name is one of the predefined metrics to watch.\\n6. If the metric value is not null, process the message by saving the metric to the database.\\n7. If the serial number exists in the database, create a new `IntelMetric` object and save it.\\n8. If the serial number does not exist in the database, create a new `IntelObject` object, add the `IntelMetric` to it, and save it.\\n9. Set the `processed` variable to true.\\n10. Catch any exceptions that occur during the processing and print the error message.\\n11. Return the `processed` variable indicating whether the message was successfully processed.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the processing steps in processMessage?\"\n",
    "result = qa.invoke({\"input\": question})\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a43248fd-e1db-49c8-a4b6-243bbea74173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The processing steps in the `processMessage` method are as follows:\n",
      "\n",
      "1. Parse the message JSON and extract the required fields such as `serialNumber`, `objectType`, `objectId`, `terminalName`, `inetName`, `siteName`, `satelliteName`, `spaceCraftName`, `teleportName`, `beamName`, `serviceArea`, `customerName`, `terminalType`, `mobilityType`, `terminalModel`, `streamType`, `resolution`, and `timestamp`.\n",
      "2. Parse the timestamp string and convert it to a Date object.\n",
      "3. Extract the `metrics` JSON object from the message.\n",
      "4. Extract the metric name and value from the metrics JSON object.\n",
      "5. Check if the metric name is one of the predefined metrics to watch.\n",
      "6. If the metric value is not null, process the message by saving the metric to the database.\n",
      "7. If the serial number exists in the database, create a new `IntelMetric` object and save it.\n",
      "8. If the serial number does not exist in the database, create a new `IntelObject` object, add the `IntelMetric` to it, and save it.\n",
      "9. Set the `processed` variable to true.\n",
      "10. Catch any exceptions that occur during the processing and print the error message.\n",
      "11. Return the `processed` variable indicating whether the message was successfully processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(result[\"answer\"], 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0e9b03-b52a-491d-9034-3bab065166b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3925d309-b6a1-4c2f-8012-74dd747ffc29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be9a2b-c64f-4671-a101-f3dd6bbdc2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
