{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "354ce261-54af-445c-98e0-2c45382b0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from util.config import load_configuration\n",
    "\n",
    "PROP_FILE = 'app.properties'\n",
    "configs = load_configuration(PROP_FILE)\n",
    "\n",
    "API_TYPE = configs.get(\"API_TYPE\").data\n",
    "API_VERSION = configs.get(\"API_VERSION\").data\n",
    "API_KEY = configs.get(\"API_KEY\").data\n",
    "API_BASE = configs.get(\"API_BASE\").data\n",
    "LLM_ENGINE_GPT35_16K=configs.get(\"LLM_ENGINE_GPT35_16K\").data\n",
    "ADA_MODEL=configs.get(\"ADA_MODEL\").data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ec5390-2861-45fe-a65b-013a89960115",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "            azure_endpoint=API_BASE,\n",
    "            api_key=API_KEY,\n",
    "            azure_deployment=LLM_ENGINE_GPT35_16K,\n",
    "            openai_api_version=API_VERSION,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098d2f82-45b7-42f6-aa2e-e4435082fbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The article discusses the concept of building autonomous agents using large language models (LLMs) as their core controller. It explores the components of such agent systems, including planning, memory, and tool use. The article provides examples of proof-of-concept demos and case studies, highlighting the challenges and limitations of using LLMs in autonomous agents.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64877a15-8767-4601-9bb5-fe1667b5b678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article discusses the concept of building autonomous agents powered by large language models (LLMs) as their core controllers. It explores the components of such agents, including planning, memory, and tool use. Several proof-of-concept examples, challenges, and references are provided. The limitations of finite context length, challenges in long-term planning and task decomposition, and the reliability of natural language interfaces are discussed.\n"
     ]
    }
   ],
   "source": [
    "## Option 1. Stuff\n",
    "# When we use load_summarize_chain with chain_type=\"stuff\", we will use the StuffDocumentsChain.\n",
    "\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Define prompt\n",
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\"{text}\"\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Define StuffDocumentsChain\n",
    "stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")\n",
    "\n",
    "print(stuff_chain.run(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d86e18-7f1c-40bd-b1c3-650efb4e8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option 2. Map-Reduce\n",
    "#  we'll first map each document to an individual summary using an LLMChain. Then we'll use a ReduceDocumentsChain to combine those summaries into a single global summary.\n",
    "\n",
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Map\n",
    "map_template = \"\"\"The following is a set of documents\n",
    "{docs}\n",
    "Based on this list of docs, please identify the main themes \n",
    "Helpful Answer:\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "# Reduce\n",
    "reduce_template = \"\"\"The following is set of summaries:\n",
    "{docs}\n",
    "Take these and distill it into a final, consolidated summary of the main themes. \n",
    "Helpful Answer:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3c384c9-05c8-44b6-a847-55e6d3fa669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
    ")\n",
    "\n",
    "# Combines and iteratively reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into.\n",
    "    token_max=4000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c95156e-70b5-415b-9666-47ee99f5c1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1003, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "# Combining documents by mapping a chain over them, then combining results\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_chain,\n",
    "    # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # The variable name in the llm_chain to put the documents in\n",
    "    document_variable_name=\"docs\",\n",
    "    # Return the results of the map steps in the output\n",
    "    return_intermediate_steps=False,\n",
    ")\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "921f5df1-9e9d-4ca0-8790-32b9f83b4eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main themes identified across the set of documents are:\n",
      "\n",
      "1. LLM-powered autonomous agents: The documents discuss the concept of building autonomous agents with LLM as the core controller. They highlight the potential of LLM as a general problem solver and its application in scientific discovery, generative agents simulation, and other tasks.\n",
      "\n",
      "2. Planning and task decomposition: The importance of planning and task decomposition is emphasized. Techniques like Chain of Thought and Tree of Thoughts are mentioned for breaking down complex tasks into smaller steps. The documents also discuss the agent's ability to refine actions through self-reflection.\n",
      "\n",
      "3. Memory utilization: The agent's utilization of short-term and long-term memory is explained. This includes the use of external vector stores for information retrieval and the integration of memory for reasoning and decision-making.\n",
      "\n",
      "4. Tool use and external APIs: The capability of the agent to call external APIs for additional information and resources is described. The use of tool augmentation and external knowledge sources to improve the functionality of LLMs is also mentioned.\n",
      "\n",
      "5. Challenges and limitations: Potential challenges and limitations of LLM-powered autonomous agents are discussed, including the finite context length of LLMs, challenges in long-term planning and task decomposition, and the reliability of natural language interfaces.\n",
      "\n",
      "6. Reinforcement learning and algorithm distillation: One document explores the use of in-context reinforcement learning with algorithm distillation to improve the performance of LLMs.\n",
      "\n",
      "7. Knowledge-intensive and decision-making tasks: The documents provide examples of LLMs applied to knowledge-intensive tasks and decision-making tasks. They demonstrate the integration of self-reflection and reasoning within language models for improved performance.\n",
      "\n",
      "8. Human feedback and interaction: The interaction and collaboration between LLMs and humans are discussed, such as question-answering with human feedback and generative agents simulating human behavior.\n",
      "\n",
      "9. Vector similarity search: Efficient vector similarity search techniques and their applications are mentioned in the context of LLM-powered agents.\n",
      "\n",
      "10. Neuro-symbolic architecture: One document describes a neuro-symbolic architecture that combines LLMs with external knowledge sources and discrete reasoning.\n",
      "\n",
      "11. AI tasks and applications: The documents discuss the use of LLMs for solving various AI tasks and applications, including chemistry, scientific research, and generative agents simulation.\n",
      "\n",
      "12. Open-source projects: References are made to open-source projects related to LLMs, such as AutoGPT and GPT-Engineer.\n",
      "\n",
      "These main themes encompass the key topics discussed in the set of documents.\n"
     ]
    }
   ],
   "source": [
    "print(map_reduce_chain.run(split_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe5067f-341c-46c6-ba7d-1311ffd58977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
